{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da425ba4",
   "metadata": {},
   "source": [
    "## E-Commerce Fraud Detection Logistic Regression Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db06a6e5",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Build a logistic regression model to predict fraudulent transactions.\n",
    "* Turn the patterns we found in EDA (e.g., time, amount, device × channel, country) into a basic risk score using Logistic Regression, so we can automatically flag higher-risk transactions for extra checks.\n",
    "\n",
    "## Requirements\n",
    "* Python 3.x\n",
    "* Jupyter Notebook\n",
    "* Required libraries: pandas, numpy and scikit-learn.\n",
    "* pip install scikit-learn (bash terminal)\n",
    "\n",
    "## What this notebook does\n",
    "- Loads the cleaned dataset.\n",
    "- Prepares features (numeric + one-hot encoded categoricals) in a reproducible pipeline.\n",
    "- Trains a Logistic Regression model with class imbalance handling.\n",
    "- Evaluates performance with ROC AUC and PR AUC, plus precision/recall/F1.\n",
    "- Finds a practical decision threshold (F1-oriented) and shows the confusion matrix.\n",
    "- Lists top positive/negative coefficients to keep the model **explainable.\n",
    "\n",
    "## Notes\n",
    "- AI has been used in this section to help write and format the code and markdown. All code and explanations have been reviewed and edited by me to ensure accuracy, clarity and error free.\n",
    "- Common issue with AI: it sometimes capitalises column names when it shouldn't. for future use, ensure column names are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fbf8ea",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "- Dataset/Cleaned/cleaned_transactions.csv (must include: amount, hour, day_of_week, country, device_type, channel, coupon_applied, is_fraud)\n",
    "\n",
    "### Outputs\n",
    "- Printed metrics (ROC AUC, PR AUC, classification report, confusion matrix)\n",
    "- Suggested threshold for best F1\n",
    "- Coefficient table (feature importance)\n",
    "- (Optional) savable metrics text file for reports.\n",
    "\n",
    "### Success criteria\n",
    "- Model trains without errors using the clean dataset.\n",
    "- Reasonable discrimination on test set (non-trivial ROC AUC and PR AUC).\n",
    "- Clear, copy-paste-ready metrics and a chosen threshold to add to the README.\n",
    "- Coefficients that align with EDA insights (e.g., higher amounts → higher fraud risk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e5e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & display options\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c947db6",
   "metadata": {},
   "source": [
    "We will now load the cleaned dataset and prepare features for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d4a5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data (cleaned_transactions.csv)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure we're in the correct working directory\n",
    "current_dir = os.getcwd()\n",
    "expected_path = r\"c:\\Users\\Nine\\OneDrive\\Documents\\VS Code Projects\\E-Commerce-Fraud-Detection-Capstone\\E-Commerce-Fraud-Detection-Capstone\"\n",
    "\n",
    "# If we're in the jupyter_notebooks subdirectory, move up one level\n",
    "if current_dir.endswith(\"jupyter_notebooks\"):\n",
    "    os.chdir(os.path.dirname(current_dir))\n",
    "    print(f\"Changed working directory from: {current_dir}\")\n",
    "    print(f\"                           to: {os.getcwd()}\")\n",
    "\n",
    "# Double check we're in the right directory for this project\n",
    "if os.getcwd() != expected_path:\n",
    "    os.chdir(expected_path)\n",
    "    print(f\"Corrected working directory to: {expected_path}\")\n",
    "\n",
    "# Load the cleaned dataset\n",
    "data_path = Path(\"DataSet/Cleaned/cleaned_transactions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7ba7754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>country</th>\n",
       "      <th>device</th>\n",
       "      <th>channel</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>coupon_applied</th>\n",
       "      <th>num_items</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6253</td>\n",
       "      <td>3594</td>\n",
       "      <td>2023-01-28 06:04:00</td>\n",
       "      <td>125.79</td>\n",
       "      <td>US</td>\n",
       "      <td>mobile</td>\n",
       "      <td>ads</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4685</td>\n",
       "      <td>2502</td>\n",
       "      <td>2023-04-27 21:32:00</td>\n",
       "      <td>153.40</td>\n",
       "      <td>DE</td>\n",
       "      <td>mobile</td>\n",
       "      <td>web</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1732</td>\n",
       "      <td>2287</td>\n",
       "      <td>2023-08-19 19:03:00</td>\n",
       "      <td>7.64</td>\n",
       "      <td>IN</td>\n",
       "      <td>tablet</td>\n",
       "      <td>app</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4743</td>\n",
       "      <td>3043</td>\n",
       "      <td>2023-03-14 04:56:00</td>\n",
       "      <td>36.36</td>\n",
       "      <td>US</td>\n",
       "      <td>mobile</td>\n",
       "      <td>web</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4522</td>\n",
       "      <td>4629</td>\n",
       "      <td>2023-09-24 21:33:00</td>\n",
       "      <td>55.17</td>\n",
       "      <td>ES</td>\n",
       "      <td>mobile</td>\n",
       "      <td>app</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  user_id            timestamp  amount country  device channel  hour  dayofweek  coupon_applied  \\\n",
       "0            6253     3594  2023-01-28 06:04:00  125.79      US  mobile     ads     6          5               0   \n",
       "1            4685     2502  2023-04-27 21:32:00  153.40      DE  mobile     web    21          3               0   \n",
       "2            1732     2287  2023-08-19 19:03:00    7.64      IN  tablet     app    19          5               0   \n",
       "3            4743     3043  2023-03-14 04:56:00   36.36      US  mobile     web     4          1               1   \n",
       "4            4522     4629  2023-09-24 21:33:00   55.17      ES  mobile     app    21          6               0   \n",
       "\n",
       "   num_items  is_fraud  \n",
       "0          5         0  \n",
       "1          3         0  \n",
       "2          3         0  \n",
       "3          2         0  \n",
       "4          1         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4052a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud rate: 6.430% (imbalance expected)\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity checks (target & dtypes)\n",
    "\n",
    "# Target checks \n",
    "assert \"is_fraud\" in df.columns, \"Expected target column 'is_fraud' not found.\"\n",
    "\n",
    "# Make y robust to True/False/0/1/\"True\"/\"False\"\n",
    "y_raw = df[\"is_fraud\"]\n",
    "if y_raw.dtype == bool:\n",
    "    y = y_raw.astype(int)\n",
    "else:\n",
    "    y = y_raw.replace({\"True\": 1, \"False\": 0}).astype(int)\n",
    "\n",
    "# Peek class balance\n",
    "fraud_rate = y.mean()\n",
    "print(f\"Fraud rate: {fraud_rate:.3%} (imbalance expected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f9dfa",
   "metadata": {},
   "source": [
    "This confirms class imbalance and sets up the binary target correctly (0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "878197d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns for modeling: ['amount', 'hour', 'dayofweek', 'num_items', 'country', 'device', 'channel', 'coupon_applied']\n",
      "Feature matrix shape: (10000, 8)\n",
      "Data types:\n",
      "amount            float64\n",
      "hour                int64\n",
      "dayofweek           int64\n",
      "num_items           int64\n",
      "country            object\n",
      "device             object\n",
      "channel            object\n",
      "coupon_applied      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Feature selection \n",
    "candidate_cols = [\n",
    "    \"amount\", \"hour\", \"dayofweek\", \"num_items\",\n",
    "    \"country\", \"device\", \"channel\", \"coupon_applied\"\n",
    "]\n",
    "available = [c for c in candidate_cols if c in df.columns]\n",
    "print(f\"Available columns for modeling: {available}\")\n",
    "\n",
    "X = df[available].copy()\n",
    "\n",
    "# Ensure boolean becomes string for clean one-hot encoding\n",
    "if \"coupon_applied\" in X.columns and X[\"coupon_applied\"].dtype == bool:\n",
    "    X[\"coupon_applied\"] = X[\"coupon_applied\"].astype(str)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Data types:\")\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e150159",
   "metadata": {},
   "source": [
    "We mix numeric + categorical features. Booleans → strings so OHE treats them as categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef289415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 8), (2500, 8), 0.06426666666666667, 0.0644)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/test split (with stratify)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.mean(), y_test.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ec3d3",
   "metadata": {},
   "source": [
    "stratify=y preserves class imbalance proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d6b3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: pass numeric, OHE categorical\n",
    "\n",
    "# Preprocess\n",
    "numeric_features = [c for c in [\"amount\", \"hour\", \"day_of_week\"] if c in X.columns]\n",
    "categorical_features = [c for c in [\"country\", \"device_type\", \"channel\", \"coupon_applied\"] if c in X.columns]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb2d4a",
   "metadata": {},
   "source": [
    "This keeps the pipeline clean and reproducible.\n",
    "We won’t leak test info; encoding happens inside the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c841786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;prep&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;amount&#x27;, &#x27;hour&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;country&#x27;, &#x27;channel&#x27;,\n",
       "                                                   &#x27;coupon_applied&#x27;])])),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;prep&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;amount&#x27;, &#x27;hour&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;country&#x27;, &#x27;channel&#x27;,\n",
       "                                                   &#x27;coupon_applied&#x27;])])),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">prep: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, &#x27;passthrough&#x27;, [&#x27;amount&#x27;, &#x27;hour&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;country&#x27;, &#x27;channel&#x27;, &#x27;coupon_applied&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;amount&#x27;, &#x27;hour&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;country&#x27;, &#x27;channel&#x27;, &#x27;coupon_applied&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('num', 'passthrough',\n",
       "                                                  ['amount', 'hour']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['country', 'channel',\n",
       "                                                   'coupon_applied'])])),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=1000))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model: logistic regression (balanced)\n",
    "\n",
    "# Build pipeline & fit\n",
    "clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"logreg\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "291bbcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC:                0.777\n",
      "Average Precision (PR AUC): 0.31\n",
      "\n",
      "Classification Report (threshold=0.5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.973     0.784     0.868      2339\n",
      "           1      0.179     0.683     0.283       161\n",
      "\n",
      "    accuracy                          0.777      2500\n",
      "   macro avg      0.576     0.733     0.576      2500\n",
      "weighted avg      0.922     0.777     0.830      2500\n",
      "\n",
      "Confusion Matrix (threshold=0.5):\n",
      " [[1833  506]\n",
      " [  51  110]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate: ROC AUC, PR AUC, report, confusion matrix\n",
    "\n",
    "proba = clf.predict_proba(X_test)[:, 1]\n",
    "pred_05 = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"ROC AUC:               \", round(roc_auc_score(y_test, proba), 3))\n",
    "print(\"Average Precision (PR AUC):\", round(average_precision_score(y_test, proba), 3))\n",
    "print(\"\\nClassification Report (threshold=0.5):\\n\",\n",
    "      classification_report(y_test, pred_05, digits=3))\n",
    "print(\"Confusion Matrix (threshold=0.5):\\n\", confusion_matrix(y_test, pred_05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eafb8a1",
   "metadata": {},
   "source": [
    "How to interpret quickly:\n",
    "\n",
    "- ROC AUC ~ probability the model ranks a random fraud above a random non-fraud (1.0 = perfect).\n",
    "\n",
    "- PR AUC (Average Precision) is better for imbalanced data; higher is better.\n",
    "\n",
    "- Classification report shows precision/recall/F1 for each class at threshold 0.5.\n",
    "\n",
    "- Confusion matrix shows counts of TP/FP/TN/FN at that threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcdc30a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 ≈ 0.384 at threshold ≈ 0.78\n",
      "\n",
      "Classification Report (best F1 threshold):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.957     0.959     0.958      2339\n",
      "           1      0.386     0.379     0.382       161\n",
      "\n",
      "    accuracy                          0.921      2500\n",
      "   macro avg      0.672     0.669     0.670      2500\n",
      "weighted avg      0.921     0.921     0.921      2500\n",
      "\n",
      "Confusion Matrix (best F1 threshold):\n",
      " [[2242   97]\n",
      " [ 100   61]]\n"
     ]
    }
   ],
   "source": [
    "# Threshold tuning (simple F1 search)\n",
    "prec, rec, thr = precision_recall_curve(y_test, proba)\n",
    "f1_scores = 2 * (prec * rec) / (prec + rec + 1e-9)\n",
    "best_idx = np.nanargmax(f1_scores)\n",
    "best_thr = thr[max(best_idx-1, 0)]  # align size difference between thr and prec/rec\n",
    "\n",
    "print(f\"Best F1 ≈ {f1_scores[best_idx]:.3f} at threshold ≈ {best_thr:.2f}\")\n",
    "\n",
    "pred_best = (proba >= best_thr).astype(int)\n",
    "print(\"\\nClassification Report (best F1 threshold):\\n\",\n",
    "      classification_report(y_test, pred_best, digits=3))\n",
    "print(\"Confusion Matrix (best F1 threshold):\\n\", confusion_matrix(y_test, pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681c3dc",
   "metadata": {},
   "source": [
    "Why: In fraud, you often prefer higher recall (catch more fraud) while keeping precision acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e88b827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive (higher => more likely fraud):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>country_IN</td>\n",
       "      <td>0.511912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>country_BR</td>\n",
       "      <td>0.377529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>country_JP</td>\n",
       "      <td>0.172918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>channel_ads</td>\n",
       "      <td>0.083488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amount</td>\n",
       "      <td>0.015648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>country_DE</td>\n",
       "      <td>-0.007757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hour</td>\n",
       "      <td>-0.028454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>country_AU</td>\n",
       "      <td>-0.062362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>channel_email</td>\n",
       "      <td>-0.103530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>channel_social</td>\n",
       "      <td>-0.112259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature      coef\n",
       "8       country_IN  0.511912\n",
       "3       country_BR  0.377529\n",
       "9       country_JP  0.172918\n",
       "12     channel_ads  0.083488\n",
       "0           amount  0.015648\n",
       "5       country_DE -0.007757\n",
       "1             hour -0.028454\n",
       "2       country_AU -0.062362\n",
       "14   channel_email -0.103530\n",
       "15  channel_social -0.112259"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top negative (lower => less likely fraud):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>channel_social</td>\n",
       "      <td>-0.112259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>country_ES</td>\n",
       "      <td>-0.146451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>country_UK</td>\n",
       "      <td>-0.170607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>channel_web</td>\n",
       "      <td>-0.236889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>country_US</td>\n",
       "      <td>-0.284573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>coupon_applied_0</td>\n",
       "      <td>-0.343569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>channel_app</td>\n",
       "      <td>-0.375212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>coupon_applied_1</td>\n",
       "      <td>-0.400833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>country_FR</td>\n",
       "      <td>-0.411233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>country_CA</td>\n",
       "      <td>-0.723778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature      coef\n",
       "15    channel_social -0.112259\n",
       "6         country_ES -0.146451\n",
       "10        country_UK -0.170607\n",
       "16       channel_web -0.236889\n",
       "11        country_US -0.284573\n",
       "17  coupon_applied_0 -0.343569\n",
       "13       channel_app -0.375212\n",
       "18  coupon_applied_1 -0.400833\n",
       "7         country_FR -0.411233\n",
       "4         country_CA -0.723778"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# “Feature importance”: inspect coefficients\n",
    "# For logistic regression, coefficients tell you direction/strength (after OHE).\n",
    "\n",
    "ohe = clf.named_steps[\"prep\"].named_transformers_[\"cat\"]\n",
    "cat_out = []\n",
    "if categorical_features:\n",
    "    cat_out = ohe.get_feature_names_out(categorical_features).tolist()\n",
    "\n",
    "feature_names = numeric_features + cat_out\n",
    "coefs = clf.named_steps[\"logreg\"].coef_.ravel()\n",
    "\n",
    "coef_df = pd.DataFrame({\"feature\": feature_names, \"coef\": coefs}).sort_values(\"coef\", ascending=False)\n",
    "print(\"Top positive (higher => more likely fraud):\")\n",
    "display(coef_df.head(10))\n",
    "print(\"\\nTop negative (lower => less likely fraud):\")\n",
    "display(coef_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff491d0",
   "metadata": {},
   "source": [
    "How to read:\n",
    "\n",
    "- Positive coef → pushes probability up (riskier).\n",
    "\n",
    "- Negative coef → pushes probability down (safer).\n",
    "- Match these back to your EDA patterns (e.g., certain device×channel combos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd5873",
   "metadata": {},
   "source": [
    "Below i will input the optional choice if i want to save the model for future use.\n",
    "(Code block will be commented out, please remove \"#\" if you want to use it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ee490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics_txt = []\n",
    "\n",
    "#roc = roc_auc_score(y_test, proba)\n",
    "#apr = average_precision_score(y_test, proba)\n",
    "#metrics_txt.append(f\"ROC AUC: {roc:.3f}\")\n",
    "#metrics_txt.append(f\"PR AUC: {apr:.3f}\")\n",
    "\n",
    "#report_05 = classification_report(y_test, pred_05, digits=3)\n",
    "#report_best = classification_report(y_test, pred_best, digits=3)\n",
    "\n",
    "#with open(\"reports/modeling/logreg_metrics.txt\", \"w\") as f:\n",
    "#    f.write(\"\\n\".join(metrics_txt))\n",
    "#    f.write(\"\\n\\n-- Threshold 0.5 --\\n\")\n",
    "#    f.write(report_05)\n",
    "#    f.write(\"\\n\\n-- Best F1 --\\n\")\n",
    "#    f.write(report_best)\n",
    "\n",
    "#coef_df.to_csv(\"reports/modeling/logreg_coefficients.csv\", index=False)\n",
    "#print(\"Saved to reports/modeling/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
